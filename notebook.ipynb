{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.7.6 ('.venv': venv)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/Users/jiatongyu/Desktop/ddss-njfs/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import logging \n",
    "import os\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import yolov5\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.7.6 ('.venv': venv)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/Users/jiatongyu/Desktop/ddss-njfs/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "LOG_TEMPLATE = \"\\n\"+\"-\"*10+\" %s \"+\"-\"*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants\n",
    "utils/constant.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOMEPATH = \"/Users/jiatongyu/Desktop/njfs/\" #change this to your working environment \n",
    "TEST_VID_PATH = HOMEPATH + \"data/test_vid.mp4\" #TODO: delete this.\n",
    "\"\"\"\n",
    "Constants related to data preprocessing\n",
    "\"\"\"\n",
    "DP_JUMP = 5\n",
    "TASK_BLACK_FRAME = \"black frame\"    # enable to filter out black frames \n",
    "TASK_NO_PERSON = \"no person\"        # enable to filter out frame with no person \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "data/dataprep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_yolo5_model():\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        Yolo5 model. see https://github.com/fcakyon/yolov5-pip for documentation\n",
    "    \"\"\"\n",
    "    model = yolov5.load('yolov5s.pt')\n",
    "    model.conf = 0.25  # NMS confidence threshold\n",
    "    model.iou = 0.45  # NMS IoU threshold\n",
    "    model.agnostic = False  # NMS class-agnostic\n",
    "    model.multi_label = False  # NMS multiple labels per box\n",
    "    model.max_det = 100  # maximum number of detections per image\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yolov5.models.experimental'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zb/3gg6nbys6dq7d9h1gkpvt2t80000gn/T/ipykernel_12531/2060817061.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_yolo5_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/zb/3gg6nbys6dq7d9h1gkpvt2t80000gn/T/ipykernel_12531/382701106.py\u001b[0m in \u001b[0;36m_load_yolo5_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mYolo5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0msee\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mgithub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfcakyon\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0myolov5\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpip\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocumentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myolov5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolov5s.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m  \u001b[0;31m# NMS confidence threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.45\u001b[0m  \u001b[0;31m# NMS IoU threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/njfs/.venv/lib/python3.7/site-packages/yolov5/helpers.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model_path, device, autoshape, verbose)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/njfs/.venv/lib/python3.7/site-packages/yolov5/models/common.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weights, device, dnn, data, fp16)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yolov5.models.experimental'"
     ]
    }
   ],
   "source": [
    "model = _load_yolo5_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllFrames(\n",
    "  video_path:str, # full path to video to load \n",
    "  enabled_tasks:list=[TASK_BLACK_FRAME,TASK_NO_PERSON], # list of frame types to filter out. currently support black frame & no person\n",
    "  save_to_folder=False, # pickle save to local \n",
    "  folder_path:str = None, # full path to local folder to save\n",
    "  ):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    video_path: full path to video to load \n",
    "    enabled_task: list of filtering tasks. Currently support black frame and no person frame \n",
    "    folder_path: full path to local folder if save_to_folder is True\n",
    "\n",
    "  Returns:\n",
    "    frames: Dict with entries \n",
    "      \"good\": frames that passed all the filtering tasks \n",
    "      TASK_x: frames that was filtered by \n",
    "  \"\"\"\n",
    "\n",
    "  # load video.\n",
    "  logger.warning(LOG_TEMPLATE,f\"loading video from path {video_path}.\")\n",
    "  if not os.path.exists(video_path):\n",
    "    raise FileNotFoundError(f\"{video_path} does not exist.\")\n",
    "  \n",
    "  # get frames \n",
    "  count = 0\n",
    "  all_frames=[]\n",
    "\n",
    "  cap=cv2.VideoCapture(video_path)\n",
    "  while(cap.isOpened()):\n",
    "      count += 1\n",
    "      ret, frame = cap.read()\n",
    "      if ret == False: break\n",
    "      if count % DP_JUMP!= 0: continue \n",
    "      all_frames.append(frame)\n",
    "  cap.release()\n",
    "  cv2.destroyAllWindows()\n",
    "\n",
    "  # filter by task \n",
    "  frames = {}\n",
    "  frames['good']=[]\n",
    "  for task_name in enabled_tasks:\n",
    "    frames[task_name]=[]\n",
    "  \n",
    "  if TASK_NO_PERSON in enabled_tasks:\n",
    "    yolo = _load_yolo5_model()\n",
    "\n",
    "  for frame in all_frames:\n",
    "    # remove black frames \n",
    "    if TASK_BLACK_FRAME in enabled_tasks:\n",
    "      if np.average(cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)) < 12:\n",
    "        frames[TASK_BLACK_FRAME].append(frame)\n",
    "        continue \n",
    "\n",
    "    # remove frame without people \n",
    "    if TASK_NO_PERSON in enabled_tasks:\n",
    "      predictions = yolo(frame).pred[0]\n",
    "      if not 0 in predictions[:, 5]:  # person label is 0\n",
    "        frames[TASK_NO_PERSON].append(frame)\n",
    "        continue \n",
    "    \n",
    "    # good frames \n",
    "    frames['good'].append(frame)\n",
    "  \n",
    "    \n",
    "  # save to local \n",
    "  if save_to_folder:\n",
    "    if not os.path.exists(folder_path):\n",
    "      raise FileNotFoundError(f\"{folder_path} does not exist.\")\n",
    "    logger.warning(LOG_TEMPLATE,f\"Saving frames to {folder_path}.\")\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "data/visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _visualize_one_frame(frame, boxes=None, labels=None):\n",
    "    \"\"\"\n",
    "    visualize one frame sample and dump into \"./temp_vis.png\"\n",
    "    Args:\n",
    "        boxes: bounding boxes in list. If passing only one \n",
    "                bbox, pass it as [box]\n",
    "        labels: corresponding to bbox, have to be same length. \n",
    "                \n",
    "    \"\"\"\n",
    "    fig2 = plt.figure()\n",
    "    ax2 = fig2.add_subplot(111, aspect='equal')\n",
    "    ax2.imshow(frame[...,::-1])\n",
    "\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            rect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],fill=False,color='turquoise')\n",
    "            ax2.add_patch(rect)\n",
    "            \n",
    "    plt.savefig('temp_vis.png')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- loading video from path /Users/jiatongyu/Desktop/njfs/data/test_vid.mp4. ----------\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yolov5.models.experimental'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zb/3gg6nbys6dq7d9h1gkpvt2t80000gn/T/ipykernel_12531/377750557.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetAllFrames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_VID_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/zb/3gg6nbys6dq7d9h1gkpvt2t80000gn/T/ipykernel_12531/4180578270.py\u001b[0m in \u001b[0;36mgetAllFrames\u001b[0;34m(video_path, enabled_tasks, save_to_folder, folder_path)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mTASK_NO_PERSON\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menabled_tasks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0myolo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_yolo5_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_frames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/zb/3gg6nbys6dq7d9h1gkpvt2t80000gn/T/ipykernel_12531/382701106.py\u001b[0m in \u001b[0;36m_load_yolo5_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mYolo5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0msee\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mgithub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfcakyon\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0myolov5\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpip\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocumentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myolov5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolov5s.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m  \u001b[0;31m# NMS confidence threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.45\u001b[0m  \u001b[0;31m# NMS IoU threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/njfs/.venv/lib/python3.7/site-packages/yolov5/helpers.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model_path, device, autoshape, verbose)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/njfs/.venv/lib/python3.7/site-packages/yolov5/models/common.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weights, device, dnn, data, fp16)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yolov5.models.experimental'"
     ]
    }
   ],
   "source": [
    "frames = getAllFrames(TEST_VID_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames = frames \n",
    "frames = all_frames['good']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling prediction box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = _load_yolo5_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "_visualize_one_frame(frames[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(frames[10]).pred[0]\n",
    "boxes = predictions[:, :4] # x1, y1, x2, y2\n",
    "scores = predictions[:, 4]\n",
    "categories = predictions[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.where(categories==0)\n",
    "_visualize_one_frame(frames[10],boxes[i])\n",
    "[box] = boxes[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1080, 3)\n",
      "tensor([ 35.04708,  35.33896, 338.86505, 718.84888])\n"
     ]
    }
   ],
   "source": [
    "mask = np.zeros(frames[0].shape, dtype=np.uint8)\n",
    "print(mask.shape)\n",
    "print(box)\n",
    "mask = cv2.rectangle(mask,pt1=(int(box[0]),int(box[1])),pt2=(int(box[2]),int(box[3])),color=(255,255,255),thickness=-1)\n",
    "res = cv2.bitwise_and(frames[10],mask)\n",
    "_visualize_one_frame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n"
     ]
    }
   ],
   "source": [
    "print(len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = predictions.pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jiatongyu/Desktop/njfs/venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jiatongyu/Desktop/njfs/venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]),)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,1,1,1])\n",
    "np.where(a==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zb/3gg6nbys6dq7d9h1gkpvt2t80000gn/T/ipykernel_74687/2589001022.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_yolo5_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tools'"
     ]
    }
   ],
   "source": [
    "from tools.detection import load_yolo5_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_person_bbox(frames):\n",
    "    logger.warning(LOG_TEMPLATE,\"pulling person bounding boxes\")\n",
    "    yolo = YOLO._load_yolo5_model()\n",
    "    frame_slices = []\n",
    "    parent_mask = np.zeros(frames[0].shape, dtype=np.uint8)\n",
    "    for frame in tqdm(frames):\n",
    "        pred = yolo(frame).pred[0]\n",
    "        boxes = pred[:, :4] # x1, y1, x2, y2\n",
    "        categories = pred[:, 5]\n",
    "        if not 0 in categories:\n",
    "            raise ValueError(\"no empty frame allowed.\")\n",
    "        #TODO: allow multiple people in a frame DONE \n",
    "        idxs = np.where(categories==0)\n",
    "        for idx in idxs:\n",
    "            box = boxes[idx]\n",
    "            mask = cv2.rectangle(parent_mask,pt1=(int(box[0]),int(box[1])),pt2=(int(box[2]),int(box[3])),\n",
    "                color=(255,255,255),thickness=-1)\n",
    "            frame_slices.append(cv2.bitwise_and(frame,mask))\n",
    "    return frame_slices\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zb/3gg6nbys6dq7d9h1gkpvt2t80000gn/T/ipykernel_12531/4177153257.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mframe_slices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpull_person_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'frames' is not defined"
     ]
    }
   ],
   "source": [
    "frame_slices = pull_person_bbox(frames[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "795ca1a453b38a9b1b9a35e57f2393b37a3716a77068dbc107b25356fda6408f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
